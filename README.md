This paper aims to differentiate some words and / or phonemes acquired during imagined speech (their imagined thinking / utterance) from electroencephalographic signals. In order to achieve the proposed objective, the following objectives are pursued:

1. Establishment of the database: in this stage the aim is to acquire / establish the database to be used and segment it into signals obtained only during the imagined speech;
2. Data preprocessing to eliminate noise;
3. Characteristic extraction: in this stage the aim is to extract the information from the signal able to characterize the different statements;
4. Classification: the extracted features will be introduced into a neural network in order to differentiate the desired classes;
5. System performance: in this stage the determination of the system performance on the test set will be followed;


The database used is called "Kara One" and was purchased from the IT department at the University of Toronto. The information is taken after an analysis via an EEG headset. All data were recorded using the SynAmps RT amplifier and sampled at 1 kHz. Impedance levels were largely kept below 10 k. The participants in the experiment were placed in front of a monitor that displayed 7 phonemes (iy, uw, piy, tiy, diy, m, n) and 4 words derived from the Kent list of phonetically similar pairs (bed, pot, known and fruit). The choice of indications comes from the desire to maintain a relatively equal number of nasal, plosive and vocal phonemes, as well as vocal and unvoked.
